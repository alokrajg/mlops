{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfcdfd66-412e-4951-a640-3c2076cbb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6725eb5f-ca63-4ccb-a276-df1ffc7276d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8189a9c3-8555-4bc7-9304-ead30bca3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify arguments\n",
    "args = Namespace(\n",
    "    lower=True,\n",
    "    stem=False,\n",
    "    analyzer=\"char\",\n",
    "    ngram_max_range=7,\n",
    "    alpha=1e-4,\n",
    "    learning_rate=1e-1,\n",
    "    power_t=0.1,\n",
    "    num_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f77a49d-93a3-4301-b305-5ef7872ff00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tracking URI\n",
    "MODEL_REGISTRY = Path(\"experiments\")\n",
    "Path(MODEL_REGISTRY).mkdir(exist_ok=True) # create experiments dir\n",
    "mlflow.set_tracking_uri(\"file://\" + str(MODEL_REGISTRY.absolute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97242e27-99a4-4b23-8597-3042a5d5fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 2.1.1\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d4eeda-e0e0-40d2-940d-7b8a122b38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support,log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6adf876f-05fe-4f49-9f2a-68253f49973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(df, lower, stem, min_freq):\n",
    "    \"\"\"Preprocess the data.\"\"\"\n",
    "    df[\"text\"] = df.title + \" \" + df.description  # feature engineering\n",
    "    df.text = df.text.apply(clean_text, lower=lower, stem=stem)  # clean text\n",
    "    tags = Counter(df.tag.values)\n",
    "\n",
    "    # Replace OOS tags with `other`\n",
    "    oos_tags = [item for item in df.tag.unique() if item not in ACCEPTED_TAGS]\n",
    "    df.tag = df.tag.apply(lambda x: \"other\" if x in oos_tags else x)\n",
    "\n",
    "    # Replace tags below min_freq with `other`\n",
    "    tags_above_freq = Counter(tag for tag in tags.elements()\n",
    "                            if (tags[tag] >= min_freq))\n",
    "    df.tag = df.tag.apply(lambda tag: tag if tag in tags_above_freq else None)\n",
    "    df.tag = df.tag.fillna(\"other\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Accepted tags (external constraint)\n",
    "ACCEPTED_TAGS = [\"natural-language-processing\", \"computer-vision\", \"mlops\", \"graph-learning\"]\n",
    "\n",
    "# Minimum frequency required for a tag\n",
    "min_freq = 75\n",
    "\n",
    "def clean_text(text, lower=True, stem=False, stopwords=STOPWORDS):\n",
    "    \"\"\"Clean raw text.\"\"\"\n",
    "    # Lower\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    if len(stopwords):\n",
    "        pattern = re.compile(r'\\b(' + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
    "        text = pattern.sub('', text)\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(\n",
    "        r\"([!\\\"'#$%&()*\\+,-./:;<=>?@\\\\\\[\\]^_`{|}~])\", r\" \\1 \", text\n",
    "    )  # add spacing between objects to be filtered\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()  # strip white space at the ends\n",
    "\n",
    "    # Remove links\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Stemming\n",
    "    if stem:\n",
    "        text = \" \".join([stemmer.stem(word, to_lowercase=lower) for word in text.split(\" \")])\n",
    "\n",
    "    return text\n",
    "\n",
    "class LabelEncoder(object):\n",
    "    \"\"\"Encode labels into unique indices\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index or {}  # mutable defaults ;)\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "\n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\"class_to_index\": self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)\n",
    "    \n",
    "    \n",
    "def get_data_splits(X, y, train_size=0.7):\n",
    "    \"\"\"Generate balanced data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(\n",
    "        X, y, train_size=train_size, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# Custom predict function\n",
    "def custom_predict(y_prob, threshold, index):\n",
    "    \"\"\"Custom predict function that defaults\n",
    "    to an index if conditions are not met.\"\"\"\n",
    "    y_pred = [np.argmax(p) if max(p) > threshold else index for p in y_prob]\n",
    "    return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19645874-a80a-496d-88db-cabbe5a38147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args,trial=None):\n",
    "    \"\"\"Train model on data.\"\"\"\n",
    "\n",
    "    # Setup\n",
    "    df = pd.read_csv(r\"../data/labeled_projects.csv\")\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = preprocess(df, lower=True, stem=False, min_freq=min_freq)\n",
    "    label_encoder = LabelEncoder().fit(df.tag)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "        get_data_splits(X=df.text.to_numpy(), y=label_encoder.encode(df.tag))\n",
    "\n",
    "    # Tf-idf\n",
    "    vectorizer = TfidfVectorizer(analyzer=args.analyzer, ngram_range=(2,args.ngram_max_range))  # char n-grams\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_val = vectorizer.transform(X_val)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    # Oversample\n",
    "    oversample = RandomOverSampler(sampling_strategy=\"all\")\n",
    "    X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Model\n",
    "    model = SGDClassifier(\n",
    "        loss=\"log\", penalty=\"l1\", alpha=args.alpha, max_iter=1,\n",
    "        learning_rate=\"constant\", eta0=args.learning_rate, power_t=args.power_t,\n",
    "        warm_start=True)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(args.num_epochs):\n",
    "        model.fit(X_over, y_over)\n",
    "        train_loss = log_loss(y_train, model.predict_proba(X_train))\n",
    "        val_loss = log_loss(y_val, model.predict_proba(X_val))\n",
    "        if not epoch%10:\n",
    "            print(\n",
    "                f\"Epoch: {epoch:02d} | \"\n",
    "                f\"train_loss: {train_loss:.5f}, \"\n",
    "                f\"val_loss: {val_loss:.5f}\"\n",
    "            )\n",
    "\n",
    "        # Log\n",
    "        if not trial:\n",
    "            mlflow.log_metrics({\"train_loss\": train_loss, \"val_loss\": val_loss}, step=epoch)\n",
    "\n",
    "        # Pruning (for optimization in next section)\n",
    "        if trial:\n",
    "            trial.report(val_loss, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    # Threshold\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_prob = model.predict_proba(X_val)\n",
    "    args.threshold = np.quantile(\n",
    "        [y_prob[i][j] for i, j in enumerate(y_pred)], q=0.25)  # Q1\n",
    "\n",
    "    # Evaluation\n",
    "    other_index = label_encoder.class_to_index[\"other\"]\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    y_pred = custom_predict(y_prob=y_prob, threshold=args.threshold, index=other_index)\n",
    "    metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "    performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "    print (json.dumps(performance, indent=2))\n",
    "\n",
    "    return {\n",
    "        \"args\": args,\n",
    "        \"label_encoder\": label_encoder,\n",
    "        \"vectorizer\": vectorizer,\n",
    "        \"model\": model,\n",
    "        \"performance\": performance\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be5a3094-b633-4a67-bb49-a19d42e18320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/alokrajgupta/test/mlops-test/notebooks/experiments/757401905687622610', creation_time=1675516274169, experiment_id='757401905687622610', last_update_time=1675516274169, lifecycle_stage='active', name='baselines', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set experiment\n",
    "mlflow.set_experiment(experiment_name=\"baselines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe106794-cd1e-4cf3-ad52-3608f3519a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(d, filepath):\n",
    "    \"\"\"Save dict to a json file.\"\"\"\n",
    "    with open(filepath, \"w\") as fp:\n",
    "        json.dump(d, indent=2, sort_keys=False, fp=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0520159-381e-4255-9fb3-5b588a44b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | train_loss: 1.23433, val_loss: 1.23894\n",
      "Epoch: 10 | train_loss: 0.67624, val_loss: 0.69655\n",
      "Epoch: 20 | train_loss: 0.54456, val_loss: 0.57964\n",
      "Epoch: 30 | train_loss: 0.48045, val_loss: 0.52643\n",
      "Epoch: 40 | train_loss: 0.44143, val_loss: 0.49518\n",
      "Epoch: 50 | train_loss: 0.41417, val_loss: 0.47341\n",
      "Epoch: 60 | train_loss: 0.39382, val_loss: 0.45814\n",
      "Epoch: 70 | train_loss: 0.37791, val_loss: 0.44625\n",
      "Epoch: 80 | train_loss: 0.36443, val_loss: 0.43689\n",
      "Epoch: 90 | train_loss: 0.35420, val_loss: 0.42943\n",
      "{\n",
      "  \"precision\": 0.8796715060302017,\n",
      "  \"recall\": 0.7638888888888888,\n",
      "  \"f1\": 0.7937561082799719\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Tracking\n",
    "with mlflow.start_run(run_name=\"sgd-1\"):\n",
    "\n",
    "    # Train & evaluate\n",
    "    artifacts = train(args=args)\n",
    "\n",
    "    # Log key metrics\n",
    "    mlflow.log_metrics({\"precision\": artifacts[\"performance\"][\"precision\"]})\n",
    "    mlflow.log_metrics({\"recall\": artifacts[\"performance\"][\"recall\"]})\n",
    "    mlflow.log_metrics({\"f1\": artifacts[\"performance\"][\"f1\"]})\n",
    "\n",
    "    # Log artifacts\n",
    "    with tempfile.TemporaryDirectory() as dp:\n",
    "        artifacts[\"label_encoder\"].save(Path(dp, \"label_encoder.json\"))\n",
    "        joblib.dump(artifacts[\"vectorizer\"], Path(dp, \"vectorizer.pkl\"))\n",
    "        joblib.dump(artifacts[\"model\"], Path(dp, \"model.pkl\"))\n",
    "        save_dict(artifacts[\"performance\"], Path(dp, \"performance.json\"))\n",
    "        mlflow.log_artifacts(dp)\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_params(vars(artifacts[\"args\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32f4029-4cb5-4a37-92dc-1dc6a08bcc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlflow server -h 0.0.0.0 -p 8000 --backend-store-uri $PWD/experiments/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3107cc22-e54b-4d4e-9727-494eac2d9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(filepath):\n",
    "    \"\"\"Load a dict from a json file.\"\"\"\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        d = json.load(fp)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e470ebd-d566-4237-9c4e-dcc32326b23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file '/Users/alokrajgupta/test/mlops-test/notebooks/experiments/757401905687622610/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alokrajgupta/miniconda3/envs/test/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 856, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/Users/alokrajgupta/miniconda3/envs/test/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 663, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/Users/alokrajgupta/miniconda3/envs/test/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1082, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/Users/alokrajgupta/miniconda3/envs/test/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1075, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/Users/alokrajgupta/miniconda3/envs/test/lib/python3.9/site-packages/mlflow/utils/file_utils.py\", line 213, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/Users/alokrajgupta/test/mlops-test/notebooks/experiments/757401905687622610/.ipynb_checkpoints/meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Load all runs from experiment\n",
    "experiment_id = mlflow.get_experiment_by_name(\"baselines\").experiment_id\n",
    "all_runs = mlflow.search_runs(experiment_ids=experiment_id, order_by=[\"metrics.val_loss ASC\"])\n",
    "# print (all_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "118af6cf-9875-465f-b7c1-78a8ee6a03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best run\n",
    "# best_run_id = all_runs.iloc[0].run_id\n",
    "# best_run = mlflow.get_run(run_id=best_run_id)\n",
    "# client = mlflow.tracking.MlflowClient()\n",
    "# with tempfile.TemporaryDirectory() as dp:\n",
    "#     client.download_artifacts(run_id=best_run_id, path=\"\", dst_path=dp)\n",
    "#     vectorizer = joblib.load(Path(dp, \"vectorizer.pkl\"))\n",
    "#     label_encoder = LabelEncoder.load(fp=Path(dp, \"label_encoder.json\"))\n",
    "#     model = joblib.load(Path(dp, \"model.pkl\"))\n",
    "#     performance = load_dict(filepath=Path(dp, \"performance.json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54ba4b-48b8-486d-a002-9739f33f0e96",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e1a859-b062-4634-a5f0-171fbd768658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "124bdca8-0ba4-493c-b98c-f4780c00b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args, trial):\n",
    "    \"\"\"Objective function for optimization trials.\"\"\"\n",
    "    # Parameters to tune\n",
    "    args.analyzer = trial.suggest_categorical(\"analyzer\", [\"word\", \"char\", \"char_wb\"])\n",
    "    args.ngram_max_range = trial.suggest_int(\"ngram_max_range\", 3, 10)\n",
    "    args.learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-2, 1e0)\n",
    "    args.power_t = trial.suggest_uniform(\"power_t\", 0.1, 0.5)\n",
    "\n",
    "    # Train & evaluate\n",
    "    artifacts = train(args=args,trial=trial)\n",
    "\n",
    "    # Set additional attributes\n",
    "    performance = artifacts[\"performance\"]\n",
    "    print(json.dumps(performance, indent=2))\n",
    "    trial.set_user_attr(\"precision\", performance[\"precision\"])\n",
    "    trial.set_user_attr(\"recall\", performance[\"recall\"])\n",
    "    trial.set_user_attr(\"f1\", performance[\"f1\"])\n",
    "\n",
    "    return performance[\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46ff8367-e4ee-4ed2-883b-8340bc507fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyencoder import NumpyEncoder\n",
    "from optuna.integration.mlflow import MLflowCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "714ddeb8-dad4-40ae-8717-cdb82d15142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 20  # small sample for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01c195f2-24e4-47a0-8cd0-4e4d25aca173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:51,909]\u001b[0m A new study created in memory with name: optimization\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | train_loss: 1.18136, val_loss: 1.19496\n",
      "Epoch: 10 | train_loss: 0.55399, val_loss: 0.60416\n",
      "Epoch: 20 | train_loss: 0.42040, val_loss: 0.48856\n",
      "Epoch: 30 | train_loss: 0.35703, val_loss: 0.43629\n",
      "Epoch: 40 | train_loss: 0.31867, val_loss: 0.40555\n",
      "Epoch: 50 | train_loss: 0.29292, val_loss: 0.38534\n",
      "Epoch: 60 | train_loss: 0.27408, val_loss: 0.37100\n",
      "Epoch: 70 | train_loss: 0.25940, val_loss: 0.35966\n",
      "Epoch: 80 | train_loss: 0.24811, val_loss: 0.35123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:52,830]\u001b[0m Trial 0 finished with value: 0.7512827780684924 and parameters: {'analyzer': 'char', 'ngram_max_range': 4, 'learning_rate': 0.08716458913990074, 'power_t': 0.2247648043438678}. Best is trial 0 with value: 0.7512827780684924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.23876, val_loss: 0.34423\n",
      "{\n",
      "  \"precision\": 0.8642625580125579,\n",
      "  \"recall\": 0.7222222222222222,\n",
      "  \"f1\": 0.7512827780684924\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8642625580125579,\n",
      "  \"recall\": 0.7222222222222222,\n",
      "  \"f1\": 0.7512827780684924\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.25090, val_loss: 1.27463\n",
      "Epoch: 10 | train_loss: 0.65134, val_loss: 0.90028\n",
      "Epoch: 20 | train_loss: 0.48991, val_loss: 0.85803\n",
      "Epoch: 30 | train_loss: 0.41595, val_loss: 0.85901\n",
      "Epoch: 40 | train_loss: 0.37551, val_loss: 0.86910\n",
      "Epoch: 50 | train_loss: 0.34708, val_loss: 0.88039\n",
      "Epoch: 60 | train_loss: 0.33065, val_loss: 0.89184\n",
      "Epoch: 70 | train_loss: 0.31834, val_loss: 0.90110\n",
      "Epoch: 80 | train_loss: 0.30791, val_loss: 0.90941\n",
      "Epoch: 90 | train_loss: 0.30255, val_loss: 0.91752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:53,173]\u001b[0m Trial 1 finished with value: 0.6602132435465768 and parameters: {'analyzer': 'word', 'ngram_max_range': 5, 'learning_rate': 0.26745695217967985, 'power_t': 0.10355489836434235}. Best is trial 0 with value: 0.7512827780684924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8001976986982985,\n",
      "  \"recall\": 0.625,\n",
      "  \"f1\": 0.6602132435465768\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8001976986982985,\n",
      "  \"recall\": 0.625,\n",
      "  \"f1\": 0.6602132435465768\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.37877, val_loss: 1.37956\n",
      "Epoch: 10 | train_loss: 1.30068, val_loss: 1.30676\n",
      "Epoch: 20 | train_loss: 1.22400, val_loss: 1.23796\n",
      "Epoch: 30 | train_loss: 1.15427, val_loss: 1.17872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:53,561]\u001b[0m Trial 2 finished with value: 0.6944460688758933 and parameters: {'analyzer': 'word', 'ngram_max_range': 6, 'learning_rate': 0.017974075165303863, 'power_t': 0.24924802934267862}. Best is trial 0 with value: 0.7512827780684924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | train_loss: 1.09150, val_loss: 1.12842\n",
      "Epoch: 50 | train_loss: 1.03586, val_loss: 1.08595\n",
      "Epoch: 60 | train_loss: 0.98640, val_loss: 1.05027\n",
      "Epoch: 70 | train_loss: 0.94232, val_loss: 1.01981\n",
      "Epoch: 80 | train_loss: 0.90301, val_loss: 0.99370\n",
      "Epoch: 90 | train_loss: 0.86741, val_loss: 0.97141\n",
      "{\n",
      "  \"precision\": 0.7901235265365699,\n",
      "  \"recall\": 0.6666666666666666,\n",
      "  \"f1\": 0.6944460688758933\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.7901235265365699,\n",
      "  \"recall\": 0.6666666666666666,\n",
      "  \"f1\": 0.6944460688758933\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.29661, val_loss: 1.30367\n",
      "Epoch: 10 | train_loss: 0.76971, val_loss: 0.90992\n",
      "Epoch: 20 | train_loss: 0.58303, val_loss: 0.80982\n",
      "Epoch: 30 | train_loss: 0.48791, val_loss: 0.77260\n",
      "Epoch: 40 | train_loss: 0.43218, val_loss: 0.75668\n",
      "Epoch: 50 | train_loss: 0.39587, val_loss: 0.74994\n",
      "Epoch: 60 | train_loss: 0.37159, val_loss: 0.74846\n",
      "Epoch: 70 | train_loss: 0.35204, val_loss: 0.74877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:53,920]\u001b[0m Trial 3 finished with value: 0.7254660910574889 and parameters: {'analyzer': 'word', 'ngram_max_range': 5, 'learning_rate': 0.1804275658227044, 'power_t': 0.2983442872419482}. Best is trial 0 with value: 0.7512827780684924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | train_loss: 0.33701, val_loss: 0.74895\n",
      "Epoch: 90 | train_loss: 0.32620, val_loss: 0.75072\n",
      "{\n",
      "  \"precision\": 0.8197653295214271,\n",
      "  \"recall\": 0.6944444444444444,\n",
      "  \"f1\": 0.7254660910574889\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8197653295214271,\n",
      "  \"recall\": 0.6944444444444444,\n",
      "  \"f1\": 0.7254660910574889\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.54102, val_loss: 0.67715\n",
      "Epoch: 10 | train_loss: 0.18473, val_loss: 0.43338\n",
      "Epoch: 20 | train_loss: 0.15029, val_loss: 0.41687\n",
      "Epoch: 30 | train_loss: 0.13873, val_loss: 0.41190\n",
      "Epoch: 40 | train_loss: 0.12639, val_loss: 0.40846\n",
      "Epoch: 50 | train_loss: 0.12256, val_loss: 0.41011\n",
      "Epoch: 60 | train_loss: 0.11865, val_loss: 0.41114\n",
      "Epoch: 70 | train_loss: 0.11613, val_loss: 0.41331\n",
      "Epoch: 80 | train_loss: 0.11179, val_loss: 0.41344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:54,551]\u001b[0m Trial 4 finished with value: 0.7776440395339018 and parameters: {'analyzer': 'char', 'ngram_max_range': 3, 'learning_rate': 0.8187011957013693, 'power_t': 0.46221054324488897}. Best is trial 4 with value: 0.7776440395339018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.11180, val_loss: 0.41381\n",
      "{\n",
      "  \"precision\": 0.8914503834642724,\n",
      "  \"recall\": 0.7430555555555556,\n",
      "  \"f1\": 0.7776440395339018\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8914503834642724,\n",
      "  \"recall\": 0.7430555555555556,\n",
      "  \"f1\": 0.7776440395339018\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.20769, val_loss: 1.23733\n",
      "Epoch: 10 | train_loss: 0.62988, val_loss: 0.74900\n",
      "Epoch: 20 | train_loss: 0.50105, val_loss: 0.64661\n",
      "Epoch: 30 | train_loss: 0.43655, val_loss: 0.59668\n",
      "Epoch: 40 | train_loss: 0.39773, val_loss: 0.56614\n",
      "Epoch: 50 | train_loss: 0.37048, val_loss: 0.54480\n",
      "Epoch: 60 | train_loss: 0.34980, val_loss: 0.52946\n",
      "Epoch: 70 | train_loss: 0.33405, val_loss: 0.51744\n",
      "Epoch: 80 | train_loss: 0.32165, val_loss: 0.50779\n",
      "Epoch: 90 | train_loss: 0.31110, val_loss: 0.49994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:55,852]\u001b[0m Trial 5 finished with value: 0.8138400321335625 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 10, 'learning_rate': 0.08039010509791486, 'power_t': 0.3116341846249877}. Best is trial 5 with value: 0.8138400321335625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8935619374974078,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8138400321335625\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8935619374974078,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8138400321335625\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.30540, val_loss: 1.32065\n",
      "Epoch: 10 | train_loss: 0.82423, val_loss: 0.97458\n",
      "Epoch: 20 | train_loss: 0.65026, val_loss: 0.88670\n",
      "Epoch: 30 | train_loss: 0.56268, val_loss: 0.85673\n",
      "Epoch: 40 | train_loss: 0.51122, val_loss: 0.84562\n",
      "Epoch: 50 | train_loss: 0.47744, val_loss: 0.84286\n",
      "Epoch: 60 | train_loss: 0.45344, val_loss: 0.84284\n",
      "Epoch: 70 | train_loss: 0.43658, val_loss: 0.84391\n",
      "Epoch: 80 | train_loss: 0.42458, val_loss: 0.84677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:56,300]\u001b[0m Trial 6 finished with value: 0.7450401297172765 and parameters: {'analyzer': 'word', 'ngram_max_range': 8, 'learning_rate': 0.1946134411675939, 'power_t': 0.4139953839336108}. Best is trial 5 with value: 0.8138400321335625.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 12:11:56,429]\u001b[0m Trial 7 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.41508, val_loss: 0.84953\n",
      "{\n",
      "  \"precision\": 0.8602175602175602,\n",
      "  \"recall\": 0.7152777777777778,\n",
      "  \"f1\": 0.7450401297172765\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8602175602175602,\n",
      "  \"recall\": 0.7152777777777778,\n",
      "  \"f1\": 0.7450401297172765\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.81777, val_loss: 0.93179\n",
      "Epoch: 00 | train_loss: 1.10834, val_loss: 1.18253\n",
      "Epoch: 10 | train_loss: 0.53471, val_loss: 0.86667\n",
      "Epoch: 20 | train_loss: 0.45512, val_loss: 0.88009\n",
      "Epoch: 30 | train_loss: 0.42513, val_loss: 0.89998\n",
      "Epoch: 40 | train_loss: 0.40300, val_loss: 0.91915\n",
      "Epoch: 50 | train_loss: 0.39306, val_loss: 0.93750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:56,927]\u001b[0m Trial 8 finished with value: 0.649214701987682 and parameters: {'analyzer': 'word', 'ngram_max_range': 10, 'learning_rate': 0.7039102223514723, 'power_t': 0.21556833797404892}. Best is trial 5 with value: 0.8138400321335625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | train_loss: 0.37735, val_loss: 0.95397\n",
      "Epoch: 70 | train_loss: 0.36391, val_loss: 0.96569\n",
      "Epoch: 80 | train_loss: 0.35561, val_loss: 0.97704\n",
      "Epoch: 90 | train_loss: 0.34960, val_loss: 0.98709\n",
      "{\n",
      "  \"precision\": 0.7829431484694642,\n",
      "  \"recall\": 0.625,\n",
      "  \"f1\": 0.649214701987682\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.7829431484694642,\n",
      "  \"recall\": 0.625,\n",
      "  \"f1\": 0.649214701987682\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.27672, val_loss: 1.29041\n",
      "Epoch: 10 | train_loss: 0.69973, val_loss: 0.92666\n",
      "Epoch: 20 | train_loss: 0.51671, val_loss: 0.87071\n",
      "Epoch: 30 | train_loss: 0.42898, val_loss: 0.86694\n",
      "Epoch: 40 | train_loss: 0.37698, val_loss: 0.87683\n",
      "Epoch: 50 | train_loss: 0.34354, val_loss: 0.88902\n",
      "Epoch: 60 | train_loss: 0.31984, val_loss: 0.90169\n",
      "Epoch: 70 | train_loss: 0.30273, val_loss: 0.91437\n",
      "Epoch: 80 | train_loss: 0.29038, val_loss: 0.92584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:57,245]\u001b[0m Trial 9 finished with value: 0.6858520623439249 and parameters: {'analyzer': 'word', 'ngram_max_range': 4, 'learning_rate': 0.1942570109068206, 'power_t': 0.2331847233532298}. Best is trial 5 with value: 0.8138400321335625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.28079, val_loss: 0.93576\n",
      "{\n",
      "  \"precision\": 0.8099262397991213,\n",
      "  \"recall\": 0.6458333333333334,\n",
      "  \"f1\": 0.6858520623439249\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8099262397991213,\n",
      "  \"recall\": 0.6458333333333334,\n",
      "  \"f1\": 0.6858520623439249\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.31455, val_loss: 1.33141\n",
      "Epoch: 10 | train_loss: 0.86162, val_loss: 0.95270\n",
      "Epoch: 20 | train_loss: 0.69372, val_loss: 0.80656\n",
      "Epoch: 30 | train_loss: 0.60472, val_loss: 0.73081\n",
      "Epoch: 40 | train_loss: 0.54779, val_loss: 0.68355\n",
      "Epoch: 50 | train_loss: 0.50689, val_loss: 0.65037\n",
      "Epoch: 60 | train_loss: 0.47601, val_loss: 0.62594\n",
      "Epoch: 70 | train_loss: 0.45162, val_loss: 0.60701\n",
      "Epoch: 80 | train_loss: 0.43175, val_loss: 0.59204\n",
      "Epoch: 90 | train_loss: 0.41528, val_loss: 0.57971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:58,571]\u001b[0m Trial 10 finished with value: 0.8017229320012969 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 10, 'learning_rate': 0.03292221034891384, 'power_t': 0.3510625165479022}. Best is trial 5 with value: 0.8138400321335625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8878264023210831,\n",
      "  \"recall\": 0.7847222222222222,\n",
      "  \"f1\": 0.8017229320012969\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8878264023210831,\n",
      "  \"recall\": 0.7847222222222222,\n",
      "  \"f1\": 0.8017229320012969\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.32194, val_loss: 1.32284\n",
      "Epoch: 10 | train_loss: 0.88957, val_loss: 0.88581\n",
      "Epoch: 20 | train_loss: 0.72065, val_loss: 0.72546\n",
      "Epoch: 30 | train_loss: 0.62906, val_loss: 0.64302\n",
      "Epoch: 40 | train_loss: 0.57002, val_loss: 0.59206\n",
      "Epoch: 50 | train_loss: 0.52784, val_loss: 0.55679\n",
      "Epoch: 60 | train_loss: 0.49586, val_loss: 0.53058\n",
      "Epoch: 70 | train_loss: 0.47048, val_loss: 0.51033\n",
      "Epoch: 80 | train_loss: 0.44977, val_loss: 0.49416\n",
      "Epoch: 90 | train_loss: 0.43246, val_loss: 0.48090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:11:59,901]\u001b[0m Trial 11 finished with value: 0.7283025535126861 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 10, 'learning_rate': 0.030959247511369754, 'power_t': 0.351536113811276}. Best is trial 5 with value: 0.8138400321335625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8689727645059698,\n",
      "  \"recall\": 0.6944444444444444,\n",
      "  \"f1\": 0.7283025535126861\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8689727645059698,\n",
      "  \"recall\": 0.6944444444444444,\n",
      "  \"f1\": 0.7283025535126861\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.27833, val_loss: 1.30139\n",
      "Epoch: 10 | train_loss: 0.74840, val_loss: 0.85605\n",
      "Epoch: 20 | train_loss: 0.59261, val_loss: 0.73320\n",
      "Epoch: 30 | train_loss: 0.51350, val_loss: 0.67181\n",
      "Epoch: 40 | train_loss: 0.46399, val_loss: 0.63363\n",
      "Epoch: 50 | train_loss: 0.42928, val_loss: 0.60734\n",
      "Epoch: 60 | train_loss: 0.40351, val_loss: 0.58759\n",
      "Epoch: 70 | train_loss: 0.38330, val_loss: 0.57201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:12:01,142]\u001b[0m Trial 12 finished with value: 0.8243159365928978 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 8, 'learning_rate': 0.04637257794439374, 'power_t': 0.32504761965797657}. Best is trial 12 with value: 0.8243159365928978.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | train_loss: 0.36717, val_loss: 0.55961\n",
      "Epoch: 90 | train_loss: 0.35361, val_loss: 0.54943\n",
      "{\n",
      "  \"precision\": 0.882114292745522,\n",
      "  \"recall\": 0.8055555555555556,\n",
      "  \"f1\": 0.8243159365928978\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.882114292745522,\n",
      "  \"recall\": 0.8055555555555556,\n",
      "  \"f1\": 0.8243159365928978\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.20432, val_loss: 1.22460\n",
      "Epoch: 10 | train_loss: 0.61745, val_loss: 0.69402\n",
      "Epoch: 20 | train_loss: 0.48990, val_loss: 0.58329\n",
      "Epoch: 30 | train_loss: 0.42791, val_loss: 0.53117\n",
      "Epoch: 40 | train_loss: 0.38917, val_loss: 0.49967\n",
      "Epoch: 50 | train_loss: 0.36301, val_loss: 0.47850\n",
      "Epoch: 60 | train_loss: 0.34324, val_loss: 0.46298\n",
      "Epoch: 70 | train_loss: 0.32779, val_loss: 0.45150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:12:02,373]\u001b[0m Trial 13 finished with value: 0.814680427887975 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 8, 'learning_rate': 0.07896784245850681, 'power_t': 0.3082965681460817}. Best is trial 12 with value: 0.8243159365928978.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | train_loss: 0.31532, val_loss: 0.44223\n",
      "Epoch: 90 | train_loss: 0.30493, val_loss: 0.43481\n",
      "{\n",
      "  \"precision\": 0.8838348765432098,\n",
      "  \"recall\": 0.7986111111111112,\n",
      "  \"f1\": 0.814680427887975\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8838348765432098,\n",
      "  \"recall\": 0.7986111111111112,\n",
      "  \"f1\": 0.814680427887975\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.27661, val_loss: 1.29705\n",
      "Epoch: 10 | train_loss: 0.73611, val_loss: 0.87317\n",
      "Epoch: 20 | train_loss: 0.57997, val_loss: 0.76292\n",
      "Epoch: 30 | train_loss: 0.50159, val_loss: 0.71090\n",
      "Epoch: 40 | train_loss: 0.45315, val_loss: 0.67977\n",
      "Epoch: 50 | train_loss: 0.41907, val_loss: 0.65808\n",
      "Epoch: 60 | train_loss: 0.39359, val_loss: 0.64245\n",
      "Epoch: 70 | train_loss: 0.37393, val_loss: 0.63067\n",
      "Epoch: 80 | train_loss: 0.35791, val_loss: 0.62130\n",
      "Epoch: 90 | train_loss: 0.34466, val_loss: 0.61380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:12:03,620]\u001b[0m Trial 14 finished with value: 0.8143817126529893 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 8, 'learning_rate': 0.04707005673215154, 'power_t': 0.15850194539639184}. Best is trial 12 with value: 0.8243159365928978.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8919082125603865,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8143817126529893\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8919082125603865,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8143817126529893\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.36305, val_loss: 1.36531\n",
      "Epoch: 10 | train_loss: 1.13120, val_loss: 1.14838\n",
      "Epoch: 20 | train_loss: 0.97304, val_loss: 0.99817\n",
      "Epoch: 30 | train_loss: 0.86693, val_loss: 0.89842\n",
      "Epoch: 40 | train_loss: 0.79097, val_loss: 0.82823\n",
      "Epoch: 50 | train_loss: 0.73380, val_loss: 0.77634\n",
      "Epoch: 60 | train_loss: 0.68879, val_loss: 0.73609\n",
      "Epoch: 70 | train_loss: 0.65204, val_loss: 0.70370\n",
      "Epoch: 80 | train_loss: 0.62150, val_loss: 0.67699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:12:04,845]\u001b[0m Trial 15 finished with value: 0.701228555395222 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 8, 'learning_rate': 0.010635672490824734, 'power_t': 0.4953561697480423}. Best is trial 12 with value: 0.8243159365928978.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.59561, val_loss: 0.65457\n",
      "{\n",
      "  \"precision\": 0.8227832104172434,\n",
      "  \"recall\": 0.6666666666666666,\n",
      "  \"f1\": 0.701228555395222\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8227832104172434,\n",
      "  \"recall\": 0.6666666666666666,\n",
      "  \"f1\": 0.701228555395222\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.25535, val_loss: 1.26906\n",
      "Epoch: 10 | train_loss: 0.69018, val_loss: 0.75540\n",
      "Epoch: 20 | train_loss: 0.53889, val_loss: 0.62950\n",
      "Epoch: 30 | train_loss: 0.46408, val_loss: 0.56929\n",
      "Epoch: 40 | train_loss: 0.41801, val_loss: 0.53326\n",
      "Epoch: 50 | train_loss: 0.38610, val_loss: 0.50858\n",
      "Epoch: 60 | train_loss: 0.36264, val_loss: 0.49049\n",
      "Epoch: 70 | train_loss: 0.34462, val_loss: 0.47645\n",
      "Epoch: 80 | train_loss: 0.32993, val_loss: 0.46482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:12:06,017]\u001b[0m Trial 16 finished with value: 0.783982914581506 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 7, 'learning_rate': 0.054976652400194705, 'power_t': 0.29137085141894276}. Best is trial 12 with value: 0.8243159365928978.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.31773, val_loss: 0.45491\n",
      "{\n",
      "  \"precision\": 0.8881302521008404,\n",
      "  \"recall\": 0.7569444444444444,\n",
      "  \"f1\": 0.783982914581506\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8881302521008404,\n",
      "  \"recall\": 0.7569444444444444,\n",
      "  \"f1\": 0.783982914581506\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.33018, val_loss: 1.33960\n",
      "Epoch: 10 | train_loss: 0.91265, val_loss: 0.98566\n",
      "Epoch: 20 | train_loss: 0.73311, val_loss: 0.83542\n",
      "Epoch: 30 | train_loss: 0.63410, val_loss: 0.75360\n",
      "Epoch: 40 | train_loss: 0.57002, val_loss: 0.70117\n",
      "Epoch: 50 | train_loss: 0.52429, val_loss: 0.66409\n",
      "Epoch: 60 | train_loss: 0.48946, val_loss: 0.63646\n",
      "Epoch: 70 | train_loss: 0.46204, val_loss: 0.61515\n",
      "Epoch: 80 | train_loss: 0.43950, val_loss: 0.59778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:12:07,198]\u001b[0m Trial 17 finished with value: 0.8310313266777816 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 7, 'learning_rate': 0.024890198831893116, 'power_t': 0.3955581983319367}. Best is trial 17 with value: 0.8310313266777816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.42083, val_loss: 0.58357\n",
      "{\n",
      "  \"precision\": 0.9114918357248887,\n",
      "  \"recall\": 0.8055555555555556,\n",
      "  \"f1\": 0.8310313266777816\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9114918357248887,\n",
      "  \"recall\": 0.8055555555555556,\n",
      "  \"f1\": 0.8310313266777816\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.34556, val_loss: 1.35282\n",
      "Epoch: 10 | train_loss: 1.00075, val_loss: 1.05751\n",
      "Epoch: 20 | train_loss: 0.82414, val_loss: 0.90503\n",
      "Epoch: 30 | train_loss: 0.72054, val_loss: 0.81766\n",
      "Epoch: 40 | train_loss: 0.65164, val_loss: 0.76132\n",
      "Epoch: 50 | train_loss: 0.60145, val_loss: 0.72128\n",
      "Epoch: 60 | train_loss: 0.56292, val_loss: 0.69106\n",
      "Epoch: 70 | train_loss: 0.53217, val_loss: 0.66749\n",
      "Epoch: 80 | train_loss: 0.50695, val_loss: 0.64860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:12:08,362]\u001b[0m Trial 18 finished with value: 0.8019109545112544 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 7, 'learning_rate': 0.01719774093680508, 'power_t': 0.3982218677990397}. Best is trial 17 with value: 0.8310313266777816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.48566, val_loss: 0.63287\n",
      "{\n",
      "  \"precision\": 0.8831790123456789,\n",
      "  \"recall\": 0.7777777777777778,\n",
      "  \"f1\": 0.8019109545112544\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8831790123456789,\n",
      "  \"recall\": 0.7777777777777778,\n",
      "  \"f1\": 0.8019109545112544\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.33441, val_loss: 1.34462\n",
      "Epoch: 10 | train_loss: 0.94384, val_loss: 1.00127\n",
      "Epoch: 20 | train_loss: 0.77064, val_loss: 0.84353\n",
      "Epoch: 30 | train_loss: 0.67413, val_loss: 0.75653\n",
      "Epoch: 40 | train_loss: 0.61040, val_loss: 0.69999\n",
      "Epoch: 50 | train_loss: 0.56465, val_loss: 0.65994\n",
      "Epoch: 60 | train_loss: 0.52980, val_loss: 0.62977\n",
      "Epoch: 70 | train_loss: 0.50199, val_loss: 0.60598\n",
      "Epoch: 80 | train_loss: 0.47911, val_loss: 0.58684\n",
      "Epoch: 90 | train_loss: 0.46015, val_loss: 0.57116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 12:12:09,690]\u001b[0m Trial 19 finished with value: 0.7871657042724058 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 9, 'learning_rate': 0.023908160183656522, 'power_t': 0.3610571722581264}. Best is trial 17 with value: 0.8310313266777816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8624508978675646,\n",
      "  \"recall\": 0.7638888888888888,\n",
      "  \"f1\": 0.7871657042724058\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8624508978675646,\n",
      "  \"recall\": 0.7638888888888888,\n",
      "  \"f1\": 0.7871657042724058\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "study = optuna.create_study(study_name=\"optimization\", direction=\"maximize\", pruner=pruner)\n",
    "mlflow_callback = MLflowCallback(\n",
    "    tracking_uri=mlflow.get_tracking_uri(), metric_name=\"f1\")\n",
    "study.optimize(lambda trial: objective(args, trial),\n",
    "            n_trials=NUM_TRIALS,\n",
    "            callbacks=[mlflow_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "320938f3-296c-473f-ba1e-b6b1ac7eb1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_analyzer</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_ngram_max_range</th>\n",
       "      <th>params_power_t</th>\n",
       "      <th>user_attrs_f1</th>\n",
       "      <th>user_attrs_precision</th>\n",
       "      <th>user_attrs_recall</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.831031</td>\n",
       "      <td>2023-02-05 12:12:06.026211</td>\n",
       "      <td>2023-02-05 12:12:07.198577</td>\n",
       "      <td>0 days 00:00:01.172366</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.024890</td>\n",
       "      <td>7</td>\n",
       "      <td>0.395558</td>\n",
       "      <td>0.831031</td>\n",
       "      <td>0.911492</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.824316</td>\n",
       "      <td>2023-02-05 12:11:59.910889</td>\n",
       "      <td>2023-02-05 12:12:01.142359</td>\n",
       "      <td>0 days 00:00:01.231470</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.046373</td>\n",
       "      <td>8</td>\n",
       "      <td>0.325048</td>\n",
       "      <td>0.824316</td>\n",
       "      <td>0.882114</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.814680</td>\n",
       "      <td>2023-02-05 12:12:01.151478</td>\n",
       "      <td>2023-02-05 12:12:02.373716</td>\n",
       "      <td>0 days 00:00:01.222238</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.078968</td>\n",
       "      <td>8</td>\n",
       "      <td>0.308297</td>\n",
       "      <td>0.814680</td>\n",
       "      <td>0.883835</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.814382</td>\n",
       "      <td>2023-02-05 12:12:02.383222</td>\n",
       "      <td>2023-02-05 12:12:03.620282</td>\n",
       "      <td>0 days 00:00:01.237060</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.047070</td>\n",
       "      <td>8</td>\n",
       "      <td>0.158502</td>\n",
       "      <td>0.814382</td>\n",
       "      <td>0.891908</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.813840</td>\n",
       "      <td>2023-02-05 12:11:54.560693</td>\n",
       "      <td>2023-02-05 12:11:55.852614</td>\n",
       "      <td>0 days 00:00:01.291921</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.080390</td>\n",
       "      <td>10</td>\n",
       "      <td>0.311634</td>\n",
       "      <td>0.813840</td>\n",
       "      <td>0.893562</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "17      17  0.831031 2023-02-05 12:12:06.026211 2023-02-05 12:12:07.198577   \n",
       "12      12  0.824316 2023-02-05 12:11:59.910889 2023-02-05 12:12:01.142359   \n",
       "13      13  0.814680 2023-02-05 12:12:01.151478 2023-02-05 12:12:02.373716   \n",
       "14      14  0.814382 2023-02-05 12:12:02.383222 2023-02-05 12:12:03.620282   \n",
       "5        5  0.813840 2023-02-05 12:11:54.560693 2023-02-05 12:11:55.852614   \n",
       "\n",
       "                 duration params_analyzer  params_learning_rate  \\\n",
       "17 0 days 00:00:01.172366         char_wb              0.024890   \n",
       "12 0 days 00:00:01.231470         char_wb              0.046373   \n",
       "13 0 days 00:00:01.222238         char_wb              0.078968   \n",
       "14 0 days 00:00:01.237060         char_wb              0.047070   \n",
       "5  0 days 00:00:01.291921         char_wb              0.080390   \n",
       "\n",
       "    params_ngram_max_range  params_power_t  user_attrs_f1  \\\n",
       "17                       7        0.395558       0.831031   \n",
       "12                       8        0.325048       0.824316   \n",
       "13                       8        0.308297       0.814680   \n",
       "14                       8        0.158502       0.814382   \n",
       "5                       10        0.311634       0.813840   \n",
       "\n",
       "    user_attrs_precision  user_attrs_recall     state  \n",
       "17              0.911492           0.805556  COMPLETE  \n",
       "12              0.882114           0.805556  COMPLETE  \n",
       "13              0.883835           0.798611  COMPLETE  \n",
       "14              0.891908           0.791667  COMPLETE  \n",
       "5               0.893562           0.791667  COMPLETE  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All trials\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df = trials_df.sort_values([\"user_attrs_f1\"], ascending=False)  # sort by metric\n",
    "trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31b083c9-7ccb-4b22-a1e1-e6dd1eb50ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value (f1): 0.8310313266777816\n",
      "Best hyperparameters: {\n",
      "  \"analyzer\": \"char_wb\",\n",
      "  \"ngram_max_range\": 7,\n",
      "  \"learning_rate\": 0.024890198831893116,\n",
      "  \"power_t\": 0.3955581983319367\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Best trial\n",
    "print (f\"Best value (f1): {study.best_trial.value}\")\n",
    "print (f\"Best hyperparameters: {json.dumps(study.best_trial.params, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed7d78ca-8c90-4e75-bd38-a06612a43c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"lower\": true,\n",
      "  \"stem\": false,\n",
      "  \"analyzer\": \"char_wb\",\n",
      "  \"ngram_max_range\": 7,\n",
      "  \"alpha\": 0.0001,\n",
      "  \"learning_rate\": 0.024890198831893116,\n",
      "  \"power_t\": 0.3955581983319367,\n",
      "  \"num_epochs\": 100,\n",
      "  \"threshold\": 0.5111814509219883\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Save best parameter values\n",
    "args = {**args.__dict__, **study.best_trial.params}\n",
    "print (json.dumps(args, indent=2, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94cde14-af5c-4697-b35f-96e91d502752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
